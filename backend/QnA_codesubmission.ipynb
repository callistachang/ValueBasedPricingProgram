{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def wiperonly(file):\n",
    "    df1= file[file.productName.str.contains(r'wiper')]\n",
    "    df2= file[file.productName.str.contains(r'Wiper')]\n",
    "    df3= file[file.productName.str.contains(r'WIPER')]\n",
    "    data= df1.append([df2, df3],ignore_index = True).drop_duplicates()\n",
    "    #data= df1.merge(df2, how='outer').drop_duplicates()\n",
    "    #data= data.merge(df3, how='outer').drop_duplicates()\n",
    "    return data\n",
    "\n",
    "def wiperdata(country, year, ccode):\n",
    "  if (year== \"2019\"):\n",
    "    file= pd.read_csv(\"/content/drive/MyDrive/Bosch/2019/08_December 2019/Lazada/02_QnA/2020-01-01_Lazada_\" +country+\"_questions_items.csv\")\n",
    "    data= wiperonly(file)\n",
    "    data.to_csv(\"/content/drive/MyDrive/Bosch/2019/08_December 2019/Lazada/02_QnA/Analysis/\"+ccode+year+\"_wiperqna.csv\" , index=False)\n",
    "    return data\n",
    "  elif (year==\"2020\"):\n",
    "    file= pd.read_csv(\"/content/drive/MyDrive/Bosch/2020/16_Oct_2020/Lazada/03_Q&A/2020-11-01_Lazada_\" + country + \"_questions_items.csv\")\n",
    "    data= wiperonly(file)\n",
    "    data.to_csv(\"/content/drive/MyDrive/Bosch/2020/16_Oct_2020/Lazada/03_Q&A/Analysis/\" +ccode+year+\"_wiperqna.csv\", index=False)\n",
    "    return data\n",
    "\n",
    "#countryCodes: ['INDO', 'MSIA', 'PHI', 'SG', 'THAI', 'VIET']\n",
    "#parameters (platform, country, year, ccode)\n",
    "#2020 Lazada Datasets\n",
    "indo2019 = wiperdata(\"Indonesia\", \"2019\", \"INDO\" )\n",
    "msia2019 = wiperdata(\"Malaysia\", \"2019\", \"MSIA\")\n",
    "phi2019 = wiperdata(\"Philippines\", \"2019\", \"PHI\")\n",
    "sin2019 = wiperdata(\"Singapore\", \"2019\", \"SG\")\n",
    "thai2019 = wiperdata(\"Thailand\", \"2019\", \"THAI\")\n",
    "viet2019 = wiperdata(\"Vietnam\", \"2019\", \"VIET\")\n",
    "\n",
    "#2020 Lazada Datasets\n",
    "indo2020 = wiperdata(\"Indonesia\", \"2020\", \"INDO\" )\n",
    "msia2020 = wiperdata(\"Malaysia\", \"2020\", \"MSIA\")\n",
    "phi2020 = wiperdata(\"Philippines\", \"2020\", \"PHI\")\n",
    "sin2020 = wiperdata(\"Singapore\", \"2020\", \"SG\")\n",
    "thai2020 = wiperdata(\"Thailand\", \"2020\", \"THAI\")\n",
    "viet2020 = wiperdata(\"Vietnam\", \"2020\", \"VIET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boschWipers = pd.read_excel(\"/content/drive/MyDrive/Bosch/Wipers__Asean.xlsx\")\n",
    "boschWipers['After sales short term'] = boschWipers['After sales short term'].str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to identify which are bosch, we will use the following:\n",
    "\n",
    "import re\n",
    "\n",
    "#relevantNrs are just long numbers, but asst may have variations that we must also check for\n",
    "\n",
    "#most product codes follow the format ABC 123 D / ABC 123, with some only being numerals\n",
    "#need to account for all possibilities: ABC123D, ABC 123D, ABC123 D, ABC 123 D, ABC-123D, ABC123-D, ABC-123-D\n",
    "\n",
    "#standardise the original bosch codes by removing all spaces\n",
    "def strip_all_except_alphanumeric(product_name):\n",
    "  # strip all characters except alphanumeric characters\n",
    "  # reference: \n",
    "  # https://stackoverflow.com/questions/1276764/stripping-everything-but-alphanumeric-chars-from-a-string-in-python\n",
    "  pattern = re.compile('[\\W_]+', re.UNICODE)\n",
    "  return pattern.sub('', str(product_name))\n",
    "\n",
    "#the following function will be used to add spaces between numbers and alphabets in the product code:\n",
    "#https://stackoverflow.com/questions/48963908/how-to-insert-space-between-alphabet-characters-and-numeric-character-using-rege\n",
    "def add_spaces(product_code):\n",
    "  resultList = []\n",
    "  regexAll = r\"(?i)(?<=\\d)(?=[a-z])|(?<=[a-z])(?=\\d)\" #adds all spaces (ABC123D → ABC 123 D)\n",
    "  regexCharNum = r\"(?i)(?<=\\d)(?=[a-z])\" #ABC123D → ABC123 D\n",
    "  regexNumChar = r\"(?i)(?<=[a-z])(?=\\d)\" #ABC123D → ABC 123D\n",
    "  insertSpace = \" \"\n",
    "  insertDash = \"-\"\n",
    "\n",
    "  result = re.sub(regexAll, insertSpace, product_code, 0)\n",
    "  if result != product_code:\n",
    "      resultList.append(result)\n",
    "  result = re.sub(regexAll, insertDash, product_code, 0)\n",
    "  if result != product_code:\n",
    "      resultList.append(result)\n",
    "\n",
    "  result = re.sub(regexCharNum, insertSpace, product_code, 0)\n",
    "  if result != product_code:\n",
    "      resultList.append(result)\n",
    "  result = re.sub(regexCharNum, insertDash, product_code, 0)\n",
    "  if result != product_code:\n",
    "      resultList.append(result)\n",
    "\n",
    "  result = re.sub(regexNumChar, insertSpace, product_code, 0)\n",
    "  if result != product_code:\n",
    "      resultList.append(result)\n",
    "\n",
    "  result = re.sub(regexNumChar, insertDash, product_code, 0)\n",
    "  if result != product_code:\n",
    "      resultList.append(result)\n",
    "\n",
    "  if resultList != []: \n",
    "    return resultList\n",
    "  else:\n",
    "    return None\n",
    "\n",
    "def getAllASST(uniqueASST):  \n",
    "  allPossibleASST = np.copy(uniqueASST) #not sure if need this\n",
    "  index = 0\n",
    "  for asst in allPossibleASST:\n",
    "    allPossibleASST[index] = strip_all_except_alphanumeric(asst)\n",
    "    index += 1\n",
    "\n",
    "  #keep a count of the original codes. we will loop through only these\n",
    "  numOriginalCodes = len(uniqueASST)\n",
    "  for index in range(numOriginalCodes):\n",
    "    newCode = add_spaces(allPossibleASST[index])\n",
    "    if newCode is not None:\n",
    "      allPossibleASST = np.append(allPossibleASST, newCode)\n",
    "\n",
    "  return allPossibleASST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/5319922/python-check-if-word-is-in-a-string\n",
    "def findWholeWord(w):\n",
    "    return re.compile(r'\\b({0})\\b'.format(w), flags=re.IGNORECASE).search\n",
    "\n",
    "def is_bosch(productName, allPossibleASST, uniqueRelevantNrs):\n",
    "  # if we are able to find the Relevant NR or ASST code in the product name,\n",
    "  # we consider it a Bosch item and set isBosch=True\n",
    "  print(\"checking: \", productName)\n",
    "  productName = str(productName)\n",
    "  for asst in allPossibleASST:\n",
    "    # print(\"asst: \", productName, asst, findWholeWord(asst)(productName))\n",
    "    if findWholeWord(asst)(productName): \n",
    "        if asst in ['500', '600', '650']: #prevent issues like productcode 500 being recognised in listings with 500 mm\n",
    "          if (findWholeWord(asst + ' mm')(productName) or findWholeWord(asst + ' cm')(productName)):\n",
    "            continue\n",
    "        print(productName, 'contains', asst)\n",
    "        return True\n",
    "  for num in uniqueRelevantNrs:\n",
    "    # print(\"relevant num: \", productName, num, findWholeWord(num)(productName))\n",
    "    if (findWholeWord(num)(productName)):\n",
    "      print(productName, 'contains', num)\n",
    "      return True\n",
    "\n",
    "  return False\n",
    "\n",
    "\n",
    "  #just append the relevant nr prod text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append prod key text for bosch products\n",
    "\n",
    "def get_lookup_category(boschCSV):\n",
    "  lookupCategory = boschCSV[['Relevant Nr', 'After sales short term', 'Relevant Nr prod key text']]\n",
    "  #standardise bosch codes\n",
    "  lookupCategory['After sales short term'] = lookupCategory['After sales short term'].apply(strip_all_except_alphanumeric)\n",
    "  #drop any duplicates\n",
    "  lookupCategory = lookupCategory.drop_duplicates()\n",
    "\n",
    "  return lookupCategory\n",
    "\n",
    "#only run this on rows where isBosch == True\n",
    "def append_prod_text(productName, allPossibleASST, uniqueRelevantNrs, lookupCategory):\n",
    "  result = []\n",
    "  productName = str(productName)\n",
    "  for asst in allPossibleASST:\n",
    "    # print(\"asst: \", productName, asst, findWholeWord(asst)(productName))\n",
    "    if findWholeWord(asst)(productName): \n",
    "        if asst in ['500', '600', '650']: #prevent issues like productcode 500 being recognised in listings with 500 mm\n",
    "          if (findWholeWord(asst + ' mm')(productName) or findWholeWord(asst + ' cm')(productName)):\n",
    "            continue\n",
    "        print(productName, 'contains', asst)\n",
    "        standardisedASST = strip_all_except_alphanumeric(asst)\n",
    "        #print(lookupCategory[lookupCategory['After sales short term'] == standardisedASST].squeeze()) #['Relevant Nr prod key text'].item()\n",
    "        result.append(lookupCategory[lookupCategory['After sales short term'] == standardisedASST]['Relevant Nr prod key text'].item())\n",
    "        result.append(lookupCategory[lookupCategory['After sales short term'] == standardisedASST]['Relevant Nr'].item())\n",
    "        result.append(lookupCategory[lookupCategory['After sales short term'] == standardisedASST]['After sales short term'].item())\n",
    "        return result\n",
    "        # return lookupCategory[lookupCategory['After sales short term'] == standardisedASST]\n",
    "  for num in uniqueRelevantNrs:\n",
    "     #print(\"relevant num: \", productName, num, findWholeWord(num)(productName))\n",
    "     if (findWholeWord(num)(productName)):\n",
    "      print(productName, 'contains', num)\n",
    "      # print(\"CHECKING: \" , lookupCategory[lookupCategory['Relevant Nr'] == num]['Relevant Nr prod key text'])\n",
    "      # print(lookupCategory[lookupCategory['Relevant Nr'] == num].squeeze()) #['Relevant Nr prod key text'].item()\n",
    "      # return lookupCategory[lookupCategory['Relevant Nr'] == num]\n",
    "      result.append(lookupCategory[lookupCategory['Relevant Nr'] == num]['Relevant Nr prod key text'].item())\n",
    "      result.append(lookupCategory[lookupCategory['Relevant Nr'] == num]['Relevant Nr'].item())\n",
    "      result.append(lookupCategory[lookupCategory['Relevant Nr'] == num]['After sales short term'].item())\n",
    "      print(result)\n",
    "      # return (lookupCategory[lookupCategory['Relevant Nr'] == num]['Relevant Nr prod key text'].item(), lookupCategory[lookupCategory['Relevant Nr'] == num]['Relevant Nr'].item(),)\n",
    "      return result\n",
    "\n",
    "  return [np.nan, np.nan, np.nan] #false?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(data): \n",
    "  data['Relevant Nr prod key text'] = data['Relevant Nr prod key text'].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
    "  data['Relevant Nr'] = data['Relevant Nr'].apply(lambda x: x[1] if isinstance(x, list) else x)\n",
    "  data['ASST'] = data['ASST'].apply(lambda x: x[2] if isinstance(x, list) else x)\n",
    "  \n",
    "def identify_subcategory(data, allPossibleASST, uniqueRelevantNrs, lookupCategory):\n",
    "  data[['Relevant Nr prod key text', 'Relevant Nr', 'ASST']] = [np.nan, np.nan, np.nan]\n",
    "  data.loc[data['isBosch'], ['Relevant Nr prod key text', 'Relevant Nr', 'ASST']] = data[data['isBosch']]['productName'].apply(lambda text: append_prod_text(text, allPossibleASST, uniqueRelevantNrs, lookupCategory))\n",
    "  extract_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortcodesearch(file):\n",
    "  temp_df= pd.DataFrame(columns= ['productName', 'brand', 'question', 'questionTimestamp', 'answer',\n",
    "       'responseTime', 'soldBy', 'sku', 'productUrl', 'categories', 'isBosch',\n",
    "       'Relevant Nr prod key text_x', 'Relevant Nr_x', 'ASST', 'RG', 'Brand',\n",
    "       'Segment', 'MV Nr', 'Vehicle typ', 'Maintenance mod range',\n",
    "       'Internal mod range', 'ESI mod range', 'Product', 'Relevant Nr_y',\n",
    "       'Relevant Nr prod key text_y', 'Unnamed: 11', 'After sales short term'])\n",
    "  for i in range(len(file)):\n",
    "    data= file.loc[i]\n",
    "    carmodel= file.Brand[i]\n",
    "    question= file.question[i]\n",
    "    upper= question.find(carmodel)\n",
    "    lowercarmodel= carmodel.lower()\n",
    "    lower= question.find(lowercarmodel)\n",
    "    oneupper= carmodel[0]+lowercarmodel[1:]\n",
    "    oneupper_find= question.find(oneupper)\n",
    "    if (upper!= -1 or lower!=-1 or oneupper_find!=-1):\n",
    "      temp_df= temp_df.append(data)\n",
    "  return (temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookcat= get_lookup_category(boschWipers)\n",
    "incorrect_data = [38327, 13890, 1665, 184, 52, 842, 36613, 14565, 36644, 29841, 33588, 7526, 10686, 8164, 29034, 6676, 7502, 7535, 7574, 7518, 7575, 834, 2444, 185, 922, 783, 1108, 13633, 795, 324, 117, 313, 7949, 881, 29144, 3402, 20673, 7708, 38202, 20351, 3410, 2957, 539, 3520, 293, 4273, 15269, 247, 1869, 949, 2924, 3779, 1743, 4622, 1228, 238, 1083, 1187, 3521, 1229, 33955, 926, 294, 3406, 4334, 3352, 351, 295, 8930, 17745, 3975, 2409, 315, 14040, 9, 9880, 32, 658, 827, 1, 22606, 892, 34, 3094, 916, 11597, 396, 1668, 7267, 1670, 326, 57, 1084, 629, 304, 924, 7269, 4094, 935, 3750, 1673, 1679, 317, 2, 815, 3066, 308, 820, 22608, 18, 3095, 920, 1674, 2873, 7165, 320, 4, 321, 638, 13, 22609, 14, 1599, 20, 1645, 13779, 13780, 17726, 13773, 8799, 8798, 14133, 8759]\n",
    "lookcat = lookcat.drop(index=incorrect_data)\n",
    "lookcat= lookcat.reset_index(drop=True)\n",
    "allPossibleASST= lookcat['After sales short term']\n",
    "uniqueRelevantNrs= lookcat['Relevant Nr']\n",
    "lookupCategory= lookcat['Relevant Nr prod key text']\n",
    "lookupCategory= lookupCategory.drop(index=incorrect_data).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indonesia "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a sample of how to run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indo2020\n",
    "indo2020['isBosch']= indo2020['productName'].apply(lambda productName : is_bosch(productName, allPossibleASST, uniqueRelevantNrs))\n",
    "identify_subcategory(indo2020,allPossibleASST, uniqueRelevantNrs, lookcat)\n",
    "indo2020= indo2020.dropna(subset= ['ASST']).reset_index(drop=True)\n",
    "indo2020merge = pd.merge(indo2020, boschWipers, left_on='ASST', right_on='After sales short term')\n",
    "#for indo2020\n",
    "indo2020merge_car=shortcodesearch(indo2020merge)\n",
    "indo2020merge_car= indo2020merge_car.reset_index(drop=True)\n",
    "new = indo2020merge_car[\"Relevant Nr prod key text_x\"].str.split(\",\", n = 1, expand = True) \n",
    "indo2020merge_car[\"Relevant Nr prod key text_x\"]= new[0]\n",
    "indo2020merge_car[\"Relevant Nr prod key text_y\"]= new[1]\n",
    "indo2020merge_car=indo2020merge_car.drop_duplicates(subset=['productName', 'question', 'After sales short term', 'Brand'], keep='first').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g= indo2020merge_car.groupby('Relevant Nr prod key text_x')\n",
    "g.ngroups\n",
    "g.apply(lambda x: x.to_csv(r'/content/drive/MyDrive/Bosch/QnA stuff/Data/Indonesia/2020/indo2020_{}.csv'.format(x.name), index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "##########\n",
    "directory = '/content/drive/MyDrive/Bosch/QnA stuff/Data/Indonesia/2020'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      print(filename)\n",
    "      file= pd.read_csv(\"/content/drive/MyDrive/Bosch/QnA stuff/Data/Indonesia/2020/\"+filename)\n",
    "      valcount= file.value_counts(subset=['Brand'])\n",
    "      print(valcount)\n",
    "      carmodels= valcount.index\n",
    "      listofsubcat=[]\n",
    "      for i in range(len(carmodels)):\n",
    "        car= carmodels[i][0]\n",
    "        listofsubcat.append(car)\n",
    "      sub= file['Relevant Nr prod key text_x'][0]\n",
    "      df= pd.DataFrame(columns= ['Brand','subcat', 'frequency'])\n",
    "      for x in range(len(listofsubcat)):\n",
    "        brand= listofsubcat[x]\n",
    "        freq= valcount[x]\n",
    "        df = df.append(\n",
    "            {'Brand': brand,\n",
    "            'subcat': sub,\n",
    "              'frequency': freq\n",
    "              }, ignore_index=True)\n",
    "      if (df is not None):\n",
    "        #print(df)\n",
    "        name= \"/content/drive/MyDrive/Bosch/QnA stuff/Indonesia/\"+filename\n",
    "        name= str(name)\n",
    "        #print(name)\n",
    "        df.to_csv(name, index=False)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Philippines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#phi2020\n",
    "phi2020['isBosch']= phi2020['productName'].apply(lambda productName : is_bosch(productName, allPossibleASST, uniqueRelevantNrs))\n",
    "identify_subcategory(phi2020,allPossibleASST, uniqueRelevantNrs, lookcat)\n",
    "phi2020_merged= phi2020.dropna(subset= ['ASST']).reset_index(drop=True)\n",
    "phi2020merge = pd.merge(phi2020, boschWipers, left_on='ASST', right_on='After sales short term')\n",
    "phi2020merge_car=shortcodesearch(phi2020merge)\n",
    "phi2020merge_car= phi2020merge_car.reset_index(drop=True)\n",
    "new = phi2020merge_car[\"Relevant Nr prod key text_x\"].str.split(\",\", n = 1, expand = True) \n",
    "phi2020merge_car[\"Relevant Nr prod key text_x\"]= new[0]\n",
    "phi2020merge_car[\"Relevant Nr prod key text_y\"]= new[1]\n",
    "phi2020merge_car=phi2020merge_car.drop_duplicates(subset=['productName', 'question', 'After sales short term', 'Brand'], keep='first').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g= phi2020merge_car.groupby('Relevant Nr prod key text_x')\n",
    "g.ngroups\n",
    "g.apply(lambda x: x.to_csv(r'/content/drive/MyDrive/Bosch/QnA stuff/Data/Philippines/2020/phi2020_{}.csv'.format(x.name), index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "##########\n",
    "directory = '/content/drive/MyDrive/Bosch/QnA stuff/Data/Philippines/2020'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      print(filename)\n",
    "      file= pd.read_csv(\"/content/drive/MyDrive/Bosch/QnA stuff/Data/Philippines/2020/\"+filename)\n",
    "      valcount= file.value_counts(subset=['Brand'])\n",
    "      print(valcount)\n",
    "      carmodels= valcount.index\n",
    "      listofsubcat=[]\n",
    "      for i in range(len(carmodels)):\n",
    "        car= carmodels[i][0]\n",
    "        listofsubcat.append(car)\n",
    "      sub= file['Relevant Nr prod key text_x'][0]\n",
    "      df= pd.DataFrame(columns= ['Brand','subcat', 'frequency'])\n",
    "      for x in range(len(listofsubcat)):\n",
    "        brand= listofsubcat[x]\n",
    "        freq= valcount[x]\n",
    "        df = df.append(\n",
    "            {'Brand': brand,\n",
    "            'subcat': sub,\n",
    "              'frequency': freq\n",
    "              }, ignore_index=True)\n",
    "      if (df is not None):\n",
    "        #print(df)\n",
    "        name= \"/content/drive/MyDrive/Bosch/QnA stuff/Philippines/\"+filename\n",
    "        name= str(name)\n",
    "        #print(name)\n",
    "        df.to_csv(name, index=False)\n",
    "\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
