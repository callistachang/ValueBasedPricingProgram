{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#2019 Bosch Datasets\n",
    "bindo2019 = pd.read_csv(\"/content/drive/MyDrive/Bosch/Binned/Indonesia/2019/Cleaned/indo2019_Bosch_TRANSLATED_CLEANED.csv\")\n",
    "bmsia2019 = pd.read_csv(\"/content/drive/MyDrive/Bosch/Binned/Malaysia/2019/Cleaned/msia2019_Bosch_TRANSLATED_CLEANED.csv\")\n",
    "bphi2019 = pd.read_csv(\"/content/drive/MyDrive/Bosch/Binned/Philippines/2019/Cleaned/phi2019_Bosch_TRANSLATED_CLEANED.csv\")\n",
    "bsin2019 = pd.read_csv(\"/content/drive/MyDrive/Bosch/Binned/Singapore/2019/Cleaned/sin2019_Bosch_CLEANED.csv\")\n",
    "bthai2019 = pd.read_csv(\"/content/drive/MyDrive/Bosch/Binned/Thailand/2019/Cleaned/thai2019_Bosch_TRANSLATED_CLEANED.csv\")\n",
    "bviet2019 = pd.read_csv(\"/content/drive/MyDrive/Bosch/Binned/Vietnam/2019/Cleaned/viet2019_Bosch_TRANSLATED_CLEANED.csv\")\n",
    "\n",
    "#2020 Bosch Datasets\n",
    "bindo2020 = pd.read_csv(\"/content/drive/MyDrive/Bosch/Binned/Indonesia/2020/Cleaned/indo2020_Bosch_TRANSLATED_CLEANED.csv\")\n",
    "bmsia2020 = pd.read_csv(\"/content/drive/MyDrive/Bosch/Binned/Malaysia/2020/Cleaned/msia2020_Bosch_TRANSLATED_CLEANED.csv\")\n",
    "bphi2020 = pd.read_csv(\"/content/drive/MyDrive/Bosch/Binned/Philippines/2020/Cleaned/phi2020_Bosch_TRANSLATED_CLEANED.csv\")\n",
    "bsin2020 = pd.read_csv(\"/content/drive/MyDrive/Bosch/Binned/Singapore/2020/Cleaned/sin2020_Bosch_CLEANED.csv\")\n",
    "bthai2020 = pd.read_csv(\"/content/drive/MyDrive/Bosch/Binned/Thailand/2020/Cleaned/thai2020_Bosch_TRANSLATED_CLEANED.csv\")\n",
    "bviet2020 = pd.read_csv(\"/content/drive/MyDrive/Bosch/Binned/Vietnam/2020/Cleaned/viet2020_Bosch_TRANSLATED_CLEANED.csv\")\n",
    "\n",
    "#2019 datasets\n",
    "b2019= bindo2019.append([bmsia2019, bphi2019, bsin2019, bthai2019, bviet2019],ignore_index = True)\n",
    "b2020= bindo2020.append([bmsia2020, bphi2020, bsin2020, bthai2020, bviet2020],ignore_index = True)\n",
    "wipersexcel= pd.read_excel(\"/content/drive/MyDrive/Bosch/Wipers__Asean.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split to Positive/ Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file= pd.read_csv(\"/content/drive/MyDrive/Bosch/Sentiment Analysis stuff/Data/bosch2019all_noa.csv\")\n",
    "positive= pd.DataFrame(columns= ['originalPrice', 'price', 'productName', 'discount', 'ratingScore',\n",
    "       'url', 'platform', 'isBosch', 'productUrl', 'reviewScore', 'reviewText',\n",
    "       'reviewTimestamp', 'reviewDate', 'reviewText_Translated', 'subcat'])\n",
    "negative= pd.DataFrame(columns= ['originalPrice', 'price', 'productName', 'discount', 'ratingScore',\n",
    "       'url', 'platform', 'isBosch', 'productUrl', 'reviewScore', 'reviewText',\n",
    "       'reviewTimestamp', 'reviewDate', 'reviewText_Translated', 'subcat'])\n",
    "for i in range(len(b2019)):\n",
    "  if (b2019['reviewScore'].iloc[i]>=3):\n",
    "    positive= positive.append(b2019.loc[i])\n",
    "  else:\n",
    "    negative= negative.append(b2019.loc[i])\n",
    "positive= positive.reset_index(drop=True)\n",
    "negative= negative.reset_index(drop=True)\n",
    "positive.to_csv(\"/content/drive/MyDrive/Bosch/Sentiment Analysis stuff/Data/wipers_bosch2019all_positive.csv\", index=False)\n",
    "negative.to_csv(\"/content/drive/MyDrive/Bosch/Sentiment Analysis stuff/Data/wipers_bosch2019all_negative.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive= pd.DataFrame(columns= ['originalPrice', 'price', 'productName', 'discount', 'ratingScore',\n",
    "       'url', 'platform', 'isBosch', 'productUrl', 'reviewScore', 'reviewText',\n",
    "       'reviewTimestamp', 'reviewDate', 'reviewText_Translated', 'subcat'])\n",
    "negative= pd.DataFrame(columns= ['originalPrice', 'price', 'productName', 'discount', 'ratingScore',\n",
    "       'url', 'platform', 'isBosch', 'productUrl', 'reviewScore', 'reviewText',\n",
    "       'reviewTimestamp', 'reviewDate', 'reviewText_Translated', 'subcat'])\n",
    "for i in range(len(b2020)):\n",
    "  if (b2020['reviewScore'].iloc[i]>=3):\n",
    "    positive= positive.append(b2020.loc[i])\n",
    "  else:\n",
    "    negative= negative.append(b2020.loc[i])\n",
    "positive= positive.reset_index(drop=True)\n",
    "negative= negative.reset_index(drop=True)\n",
    "positive.to_csv(\"/content/drive/MyDrive/Bosch/Sentiment Analysis stuff/Data/wipers_bosch2020all_positive.csv\", index=False)\n",
    "negative.to_csv(\"/content/drive/MyDrive/Bosch/Sentiment Analysis stuff/Data/wipers_bosch2020all_negative.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2019_pos= pd.read_csv(\"/content/drive/MyDrive/Bosch/Sentiment Analysis stuff/Data/wipers_bosch2019all_positive.csv\")\n",
    "b2019_neg= pd.read_csv(\"/content/drive/MyDrive/Bosch/Sentiment Analysis stuff/Data/wipers_bosch2019all_negative.csv\")\n",
    "b2020_pos= pd.read_csv(\"/content/drive/MyDrive/Bosch/Sentiment Analysis stuff/Data/wipers_bosch2020all_positive.csv\")\n",
    "b2020_neg= pd.read_csv(\"/content/drive/MyDrive/Bosch/Sentiment Analysis stuff/Data/wipers_bosch2020all_negative.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filltranslated(file):\n",
    "    file= file.dropna(subset= ['reviewText']).reset_index(drop=True)\n",
    "    for i in range(len(file)):\n",
    "      if pd.isna(file['reviewText_Translated'].iloc[i]):\n",
    "        file['reviewText_Translated'].iloc[i]= file['reviewText'].iloc[i]\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2019_pos= filltranslated(b2019_pos)\n",
    "b2019_neg= filltranslated(b2019_neg)\n",
    "b2020_pos= filltranslated(b2020_pos)\n",
    "b2020_neg= filltranslated(b2020_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords') #need this to define stopwords\n",
    "\n",
    "def punctuation(string): \n",
    "  \n",
    "    # punctuation marks \n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "  \n",
    "    # traverse the given string and if any punctuation \n",
    "    # marks occur replace it with null \n",
    "    for x in string.lower(): \n",
    "        if x in punctuations: \n",
    "            string = string.replace(x, \"\") \n",
    "  \n",
    "    # Print string without punctuation \n",
    "    return(string) \n",
    "\n",
    "\n",
    "def text_process(reviewText):\n",
    "  #get rid of punctuation, remove symbols\n",
    "  reviewText= re.sub('[^a-zA-Z]', ' ', reviewText.lower())\n",
    "  reviewText= re.sub(r'\\s+', ' ', reviewText)\n",
    "  #reviewText= punctuation(reviewText)\n",
    "\n",
    "  #removing stopwords\n",
    "  stop_words = set(stopwords.words('english'))  \n",
    "  word_tokens = word_tokenize(reviewText)  \n",
    "\n",
    "  filtered_sentence = [w for w in word_tokens if not w in stop_words]  \n",
    "  filtered_sentence = []  \n",
    "  for w in word_tokens:  \n",
    "      if w not in stop_words:  \n",
    "          filtered_sentence.append(w) \n",
    "  return (filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new column for summary\n",
    "b2019_pos['summary']='a'\n",
    "b2019_neg['summary']='a'\n",
    "b2020_pos['summary']='a'\n",
    "b2020_neg['summary']='a'\n",
    "\n",
    "#somehow I need to convert to string, because when I separate according to ASST csvs, the lists get trapped in string :/\n",
    "def listToString(list):  \n",
    "    # initialize an empty string \n",
    "    str1 = \" \" \n",
    "    # return string   \n",
    "    return (str1.join(list)) \n",
    "#print(listToString(s))\n",
    "\n",
    "for x in range (len(b2019_pos)):\n",
    "  b2019_pos.summary[x]= text_process(b2019_pos.reviewText_Translated[x])\n",
    "for x in range (len(b2019_neg)):\n",
    "  b2019_neg.summary[x]= text_process(b2019_neg.reviewText_Translated[x])\n",
    "for x in range (len(b2020_pos)):\n",
    "  b2020_pos.summary[x]= text_process(b2020_pos.reviewText_Translated[x])\n",
    "for x in range (len(b2020_neg)):\n",
    "  b2020_neg.summary[x]= text_process(b2020_neg.reviewText_Translated[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g= b2019_pos.groupby('ASST')\n",
    "g.ngroups\n",
    "g.apply(lambda x: x.to_csv(r'/content/drive/MyDrive/Bosch/Sentiment Analysis stuff/Data/Wipers Positive Subcat 2019/summary/wipers_bosch2019_pos_{}.csv'.format(x.name), index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g= b2019_neg.groupby('ASST')\n",
    "g.ngroups\n",
    "g.apply(lambda x: x.to_csv(r'/content/drive/MyDrive/Bosch/Sentiment Analysis stuff/Data/Wipers Negative Subcat 2019/summary/wipers_bosch2019_neg_{}.csv'.format(x.name), index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g= b2020_pos.groupby('ASST')\n",
    "g.ngroups\n",
    "g.apply(lambda x: x.to_csv(r'/content/drive/MyDrive/Bosch/Sentiment Analysis stuff/Data/Wipers Positive Subcat 2020/summary/wipers_bosch2020_pos_{}.csv'.format(x.name), index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g= b2020_neg.groupby('ASST')\n",
    "g.ngroups\n",
    "g.apply(lambda x: x.to_csv(r'/content/drive/MyDrive/Bosch/Sentiment Analysis stuff/Data/Wipers Negative Subcat 2020/summary/wipers_bosch2020_neg_{}.csv'.format(x.name), index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punctuation(string): \n",
    "  \n",
    "    # punctuation marks \n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "  \n",
    "    # traverse the given string and if any punctuation \n",
    "    # marks occur replace it with null \n",
    "    for x in string.lower(): \n",
    "        #print(x)\n",
    "        if x in punctuations: \n",
    "            string = string.replace(x, \"\") \n",
    "  \n",
    "    # Print string without punctuation \n",
    "    return(string) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "##########\n",
    "directory = '/content/drive/MyDrive/Bosch/Sentiment Analysis stuff/Data/Wipers Negative Subcat 2019/summary'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      print(filename)\n",
    "      file= pd.read_csv(\"/content/drive/MyDrive/Bosch/Sentiment Analysis stuff/Data/Wipers Negative Subcat 2019/summary/\"+filename)\n",
    "      asst= file['ASST'][0]\n",
    "      cleaned_tokens_list = []\n",
    "      for i in range(len(file)):\n",
    "        file.summary[i]= punctuation(file.summary[i])\n",
    "      listofwords= file.summary.str.split(expand=True).stack().value_counts()\n",
    "      df= pd.DataFrame(columns= ['word','ASST', 'frequency'])\n",
    "      if (len(listofwords)>=20):\n",
    "        for x in range(20):\n",
    "          word= listofwords.index[x]\n",
    "          frequency= listofwords[x]\n",
    "          df = df.append(\n",
    "              {'word': word,\n",
    "              'ASST': asst,\n",
    "                'frequency': frequency\n",
    "                }, ignore_index=True)\n",
    "      if (df is not None):\n",
    "        #print(df)\n",
    "        name= \"/content/drive/MyDrive/Bosch/Sentiment Analysis stuff/Wipers Negative Subcat 2019/\"+filename\n",
    "        name= str(name)\n",
    "        #print(name)\n",
    "        df.to_csv(name, index=False)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "##########\n",
    "directory = '/content/drive/MyDrive/Bosch/Sentiment Analysis stuff/Data/Wipers Positive Subcat 2019/summary'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      print(filename)\n",
    "      file= pd.read_csv(\"/content/drive/MyDrive/Bosch/Sentiment Analysis stuff/Data/Wipers Positive Subcat 2019/summary/\"+filename)\n",
    "      asst= file['ASST'][0]\n",
    "      cleaned_tokens_list = []\n",
    "      for i in range(len(file)):\n",
    "        file.summary[i]= punctuation(file.summary[i])\n",
    "      listofwords= file.summary.str.split(expand=True).stack().value_counts()\n",
    "      df= pd.DataFrame(columns= ['word','ASST', 'frequency'])\n",
    "      if (len(listofwords)>=20):\n",
    "        for x in range(20):\n",
    "          word= listofwords.index[x]\n",
    "          frequency= listofwords[x]\n",
    "          df = df.append(\n",
    "              {'word': word,\n",
    "              'ASST': asst,\n",
    "                'frequency': frequency\n",
    "                }, ignore_index=True)\n",
    "      if (df is not None):\n",
    "        #print(df)\n",
    "        name= \"/content/drive/MyDrive/Bosch/Sentiment Analysis stuff/Wipers Positive Subcat 2019/\"+filename\n",
    "        name= str(name)\n",
    "        #print(name)\n",
    "        df.to_csv(name, index=False)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "##########\n",
    "directory = '/content/drive/MyDrive/Bosch/Sentiment Analysis stuff/Data/Wipers Negative Subcat 2020/summary'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      print(filename)\n",
    "      file= pd.read_csv(\"/content/drive/MyDrive/Bosch/Sentiment Analysis stuff/Data/Wipers Negative Subcat 2020/summary/\"+filename)\n",
    "      asst= file['ASST'][0]\n",
    "      cleaned_tokens_list = []\n",
    "      for i in range(len(file)):\n",
    "        file.summary[i]= punctuation(file.summary[i])\n",
    "      listofwords= file.summary.str.split(expand=True).stack().value_counts()\n",
    "      df= pd.DataFrame(columns= ['word','ASST', 'frequency'])\n",
    "      if (len(listofwords)>=20):\n",
    "        for x in range(20):\n",
    "          word= listofwords.index[x]\n",
    "          frequency= listofwords[x]\n",
    "          df = df.append(\n",
    "              {'word': word,\n",
    "              'ASST': asst,\n",
    "                'frequency': frequency\n",
    "                }, ignore_index=True)\n",
    "      if (df is not None):\n",
    "        #print(df)\n",
    "        name= \"/content/drive/MyDrive/Bosch/Sentiment Analysis stuff/Wipers Negative Subcat 2020/\"+filename\n",
    "        name= str(name)\n",
    "        #print(name)\n",
    "        df.to_csv(name, index=False)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "##########\n",
    "directory = '/content/drive/MyDrive/Bosch/Sentiment Analysis stuff/Data/Wipers Positive Subcat 2020/summary'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "      print(filename)\n",
    "      file= pd.read_csv(\"/content/drive/MyDrive/Bosch/Sentiment Analysis stuff/Data/Wipers Positive Subcat 2020/summary/\"+filename)\n",
    "      asst= file['ASST'][0]\n",
    "      cleaned_tokens_list = []\n",
    "      for i in range(len(file)):\n",
    "        file.summary[i]= punctuation(file.summary[i])\n",
    "      listofwords= file.summary.str.split(expand=True).stack().value_counts()\n",
    "      df= pd.DataFrame(columns= ['word','ASST', 'frequency'])\n",
    "      if (len(listofwords)>=20):\n",
    "        for x in range(20):\n",
    "          word= listofwords.index[x]\n",
    "          frequency= listofwords[x]\n",
    "          df = df.append(\n",
    "              {'word': word,\n",
    "              'ASST': asst,\n",
    "                'frequency': frequency\n",
    "                }, ignore_index=True)\n",
    "      if (df is not None):\n",
    "        #print(df)\n",
    "        name= \"/content/drive/MyDrive/Bosch/Sentiment Analysis stuff/Wipers Positive Subcat 2020/\"+filename\n",
    "        name= str(name)\n",
    "        #print(name)\n",
    "        df.to_csv(name, index=False)\n",
    "\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
